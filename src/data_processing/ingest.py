import requests
import os
import logging
import pandas as pd



def load_data(path,url):
    logger = logging.getLogger(__name__)
    logger.info("ingest_data")

    if os.path.isfile(path):
        logger.info("find data set locally")
    else:
        logger.info("downloading data set from url")
        try:
            r = requests.get(url)
            with open(path, "wb") as f:
                f.write(r.content)
            logger.info("data set downloaded")
        except Exception as e:
            logger.error(f"download data set failed: {e}")
    return pd.read_csv(path,sep=';')


def clean_and_save_news_data(df,path):
    logger = logging.getLogger(__name__)
    logger.info("ingest_data")
    logger.info("cleaning the data")

    df = df[ df['lang'] ==  'en']
    df = df.drop('lang',axis = 1)
    df = df.drop('link',axis = 1)
    df = df.drop('domain',axis = 1)
    df = df.drop('published_date',axis = 1)
    df = df.drop_duplicates()
    logger.info("data cleaned")
    df.to_csv(path, index=False)
    logger.info("cleaned data saved")


#test drop funciton work